{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Connecting the Google Colab Notebook to my Drive"
      ],
      "metadata": {
        "id": "F-KpoLgyZ0nk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdNl_aViHVoT",
        "outputId": "7378fbe7-64ed-4851-fa71-1c6e68c98e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Historical Stock Market Data"
      ],
      "metadata": {
        "id": "d98fUkB8Z-_w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUcT228GGp0q"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# list of Indian company stock symbols (NSE/BSE)\n",
        "companies = [\n",
        "    'RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'HINDUNILVR.NS',\n",
        "    'HDFC.NS', 'KOTAKBANK.NS', 'ICICIBANK.NS', 'SBIN.NS', 'BAJFINANCE.NS',\n",
        "    'BHARTIARTL.NS', 'ITC.NS', 'ASIANPAINT.NS', 'HCLTECH.NS', 'MARUTI.NS',\n",
        "    'LT.NS', 'WIPRO.NS', 'AXISBANK.NS', 'ULTRACEMCO.NS', 'SUNPHARMA.NS',\n",
        "    'TITAN.NS', 'ADANIPORTS.NS', 'NESTLEIND.NS', 'ONGC.NS', 'BAJAJFINSV.NS',\n",
        "    'TECHM.NS', 'HDFCLIFE.NS', 'NTPC.NS', 'JSWSTEEL.NS', 'POWERGRID.NS',\n",
        "    'DIVISLAB.NS', 'SBILIFE.NS', 'GRASIM.NS', 'DRREDDY.NS', 'BRITANNIA.NS',\n",
        "    'TATAMOTORS.NS', 'HINDALCO.NS', 'COALINDIA.NS', 'TATASTEEL.NS', 'IOC.NS',\n",
        "    'BAJAJ-AUTO.NS', 'HEROMOTOCO.NS', 'EICHERMOT.NS', 'INDUSINDBK.NS', 'BPCL.NS',\n",
        "    'BHARATIARTL.NS', 'UPL.NS', 'CIPLA.NS', 'SHREECEM.NS', 'ADANIGREEN.NS',\n",
        "    'ADANITRANS.NS', 'M&M.NS', 'TATACONSUM.NS', 'BAJAJHLDNG.NS', 'DABUR.NS',\n",
        "    'GAIL.NS', 'HDFCAMC.NS', 'HINDPETRO.NS', 'NAUKRI.NS', 'BERGEPAINT.NS',\n",
        "    'PIDILITIND.NS', 'SIEMENS.NS', 'DLF.NS', 'BANDHANBNK.NS', 'MUTHOOTFIN.NS',\n",
        "    'ICICIGI.NS', 'SBICARD.NS', 'LUPIN.NS', 'HAVELLS.NS', 'COLPAL.NS',\n",
        "    'AMBUJACEM.NS', 'PGHH.NS', 'GODREJCP.NS', 'PEL.NS', 'MRF.NS',\n",
        "    'BIOCON.NS', 'MARICO.NS', 'INDIGO.NS', 'NMDC.NS', 'BEL.NS',\n",
        "    'APOLLOHOSP.NS', 'JUBLFOOD.NS', 'BOSCHLTD.NS', 'ICICIPRULI.NS', 'GLAND.NS',\n",
        "    'LTI.NS', 'MPHASIS.NS', 'VEDL.NS', 'AUBANK.NS', 'TORNTPHARM.NS',\n",
        "    'ACC.NS', 'TATAPOWER.NS', 'BANKBARODA.NS', 'ATGL.NS', 'MINDTREE.NS',\n",
        "    'PIDILITIND.NS', 'PERSISTENT.NS', 'IGL.NS', 'HAL.NS', 'ICICIBANK.NS'\n",
        "]\n",
        "\n",
        "\n",
        "# defining the start and end dates for the historical data\n",
        "start_date = '2020-01-01'\n",
        "end_date = '2023-01-01'\n",
        "\n",
        "# creating an empty DataFrame to store all the data\n",
        "all_data = pd.DataFrame()\n",
        "\n",
        "for symbol in companies:\n",
        "    # fetching historical data from Yahoo Finance\n",
        "    data = yf.download(symbol, start=start_date, end=end_date)\n",
        "\n",
        "    # adding a column for the company symbol\n",
        "    data['Symbol'] = symbol\n",
        "\n",
        "    # appending the data to the main DataFrame\n",
        "    all_data = all_data.append(data)\n",
        "\n",
        "# resetting the index\n",
        "all_data.reset_index(inplace=True)\n",
        "\n",
        "# displaying the first few rows of the DataFrame\n",
        "print(all_data.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfpA4h0-HLez"
      },
      "outputs": [],
      "source": [
        "# inspecting the first few columns of the data\n",
        "all_data.head()\n",
        "# saving the data to my drive\n",
        "all_data.to_csv('/content/drive/MyDrive/Fall 2023/Applied Data Science/datasets/indian_stock_market_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iTYnCNwSaHHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing the data - basic data cleaning"
      ],
      "metadata": {
        "id": "_-9_WE3EaM0X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKM4uJY3IlIi",
        "outputId": "6c22c4e7-99d1-4771-a259-6347315db76d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the transformed data:\n"
          ]
        }
      ],
      "source": [
        "# importing necessary libraries\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# loading the dataset that contains historical data\n",
        "file_path = '/content/drive/MyDrive/Fall 2023/Applied Data Science/datasets/indian_stock_market_data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# basic data cleaning\n",
        "# converting 'Date' to datetime format\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "# sorting data by 'Date' and 'Symbol'\n",
        "data.sort_values(by=['Symbol', 'Date'], inplace=True)\n",
        "\n",
        "# resetting index after sorting\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# handling missing values\n",
        "# checking for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# dropping rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# handling outliers\n",
        "# for financial data, it's tricky to define outliers without specific domain knowledge. I am not an expert in finance\n",
        "# checking how far data points are from mean to detect outliers\n",
        "for column in ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']:\n",
        "    mean = data[column].mean()\n",
        "    std = data[column].std()\n",
        "    data = data[(data[column] > (mean - 3 * std)) & (data[column] < (mean + 3 * std))]\n",
        "\n",
        "# normalize the numerical columns\n",
        "# identifying numerical columns (excluding 'Date' and 'Symbol')\n",
        "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# creating a MinMaxScaler object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# appling normalization to numerical columns\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# displaying the transformed data\n",
        "print(\"First few rows of the transformed data:\")\n",
        "data.head(10)\n",
        "\n",
        "# saving the preprocessed data back to a CSV file\n",
        "data.to_csv('/content/preprocessed_indian_stock_market_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "UHAH1LwnaS-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cl4kMNDLn-P",
        "outputId": "1a2aaa0f-79c5-41f5-c2eb-c368123452d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the transformed data with new features:\n",
            "          Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
            "14  2020-01-21  0.310253  0.303661  0.328830  0.329535   0.316067  0.004697   \n",
            "15  2020-01-22  0.312986  0.309289  0.332211  0.335850   0.322124  0.021819   \n",
            "16  2020-01-23  0.316834  0.312940  0.337340  0.341195   0.327250  0.014565   \n",
            "17  2020-01-24  0.322195  0.316172  0.341191  0.345112   0.331007  0.010302   \n",
            "18  2020-01-27  0.322878  0.317977  0.341628  0.341307   0.327357  0.007042   \n",
            "\n",
            "    Symbol  Daily_Return  High_Low_Range  7Day_MA_Close  14Day_MA_Close  \\\n",
            "14  ACC.NS      0.062147       -0.025169       0.332528        0.328611   \n",
            "15  ACC.NS      0.073050       -0.022922       0.332472        0.329110   \n",
            "16  ACC.NS      0.076889       -0.024400       0.333571        0.330259   \n",
            "17  ACC.NS      0.071126       -0.025019       0.335170        0.332337   \n",
            "18  ACC.NS      0.057075       -0.023651       0.336574        0.333817   \n",
            "\n",
            "    7Day_MA_Volume        RSI  \n",
            "14        0.007517  61.204486  \n",
            "15        0.009637  56.958933  \n",
            "16        0.010112  65.497952  \n",
            "17        0.009744  81.146966  \n",
            "18        0.009526  72.552826  \n",
            "Correlation of features with the Close price:\n",
            "Open              0.999585\n",
            "High              0.999803\n",
            "Low               0.999786\n",
            "Close             1.000000\n",
            "Adj Close         0.998777\n",
            "Volume           -0.429121\n",
            "Daily_Return      0.032669\n",
            "High_Low_Range   -0.925173\n",
            "7Day_MA_Close     0.995405\n",
            "14Day_MA_Close    0.989903\n",
            "7Day_MA_Volume   -0.465709\n",
            "RSI               0.065669\n",
            "Name: Close, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-605eed62bfdc>:52: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  correlation = preprocessed_data.corr()['Close']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# loading the cleaned dataset\n",
        "file_path = '/content/drive/MyDrive/Fall 2023/Applied Data Science/datasets/preprocessed_indian_stock_market_data.csv'  # Adjust the file path if necessary\n",
        "preprocessed_data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# calculating additional features that are commonly used in stock price analysis, based on  limited research given time constraint\n",
        "\n",
        "# 1. daily return: (Close - Open) / Open\n",
        "preprocessed_data['Daily_Return'] = (preprocessed_data['Close'] - preprocessed_data['Open']) / preprocessed_data['Open']\n",
        "\n",
        "# 2. daily high-low range: High - Low\n",
        "preprocessed_data['High_Low_Range'] = preprocessed_data['High'] - preprocessed_data['Low']\n",
        "\n",
        "# 3. 7-day moving average of close price\n",
        "preprocessed_data['7Day_MA_Close'] = preprocessed_data['Close'].rolling(window=7).mean()\n",
        "\n",
        "# 4. 14-day moving average of close price\n",
        "preprocessed_data['14Day_MA_Close'] = preprocessed_data['Close'].rolling(window=14).mean()\n",
        "\n",
        "# 5. 7-day moving average of volume\n",
        "preprocessed_data['7Day_MA_Volume'] = preprocessed_data['Volume'].rolling(window=7).mean()\n",
        "\n",
        "# 6. relative strength index (RSI) - a momentum indicator (14-day period)\n",
        "# computing daily price change\n",
        "delta = preprocessed_data['Close'].diff(1)\n",
        "delta = delta.dropna()\n",
        "\n",
        "# separating the positive and negative gains\n",
        "up = delta.clip(lower=0)\n",
        "down = -1 * delta.clip(upper=0)\n",
        "\n",
        "# calculating the average gain and loss\n",
        "roll_up = up.rolling(window=14).mean()\n",
        "roll_down = down.rolling(window=14).mean()\n",
        "\n",
        "# calculatingh the Relative Strength (RS)\n",
        "RS = roll_up / roll_down\n",
        "\n",
        "# calculating the RSI\n",
        "preprocessed_data['RSI'] = 100.0 - (100.0 / (1.0 + RS))\n",
        "\n",
        "# dropping NaN values generated by rolling mean\n",
        "preprocessed_data.dropna(inplace=True)\n",
        "\n",
        "# checking the new features\n",
        "print(\"First few rows of the transformed data with new features:\")\n",
        "print(preprocessed_data.head())\n",
        "\n",
        "# statistical analysis: correlation with close price\n",
        "correlation = preprocessed_data.corr()['Close']\n",
        "print(\"Correlation of features with the Close price:\")\n",
        "print(correlation)\n",
        "\n",
        "# saving the data with new features to a CSV file\n",
        "preprocessed_data.to_csv('/content/drive/MyDrive/Fall 2023/Applied Data Science/datasets/feature_engineered_stock_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting and Training Machine Learning Models"
      ],
      "metadata": {
        "id": "LVVsPDMKaXli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with a particular set of features"
      ],
      "metadata": {
        "id": "1eO5TlemOQJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/Fall 2023/Applied Data Science/datasets/feature_engineered_stock_data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Selecting relevant features based on correlation\n",
        "selected_features = ['Volume', 'Daily_Return', 'High_Low_Range', '7Day_MA_Close', '14Day_MA_Close', '7Day_MA_Volume', 'RSI']\n",
        "\n",
        "# Preparing the data\n",
        "X = data[selected_features]\n",
        "y = data['Close']\n",
        "\n",
        "# Handle infinite and NaN values\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.dropna(inplace=True)\n",
        "y = y.loc[X.index]  # Ensure target aligns with features after dropping NaNs\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Linear Regression Model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_predictions = lr_model.predict(X_test)\n",
        "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
        "print('Linear Regression MSE:', lr_mse)\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
        "print('Random Forest Regression MSE:', rf_mse)\n",
        "\n",
        "# Hyperparameter Tuning for Random Forest (Optional)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, 30]\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best score found: \", grid_search.best_score_)\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_rf_predictions = best_rf_model.predict(X_test)\n",
        "best_rf_mse = mean_squared_error(y_test, best_rf_predictions)\n",
        "print('Best Random Forest MSE:', best_rf_mse)\n"
      ],
      "metadata": {
        "id": "oyB198nAOVX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the models"
      ],
      "metadata": {
        "id": "b6yhHY1EamZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional imports for evaluation metrics\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate Linear Regression model\n",
        "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_predictions))\n",
        "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
        "lr_r2 = r2_score(y_test, lr_predictions)\n",
        "print('Linear Regression RMSE:', lr_rmse)\n",
        "print('Linear Regression MAE:', lr_mae)\n",
        "print('Linear Regression R-squared:', lr_r2)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
        "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
        "rf_r2 = r2_score(y_test, rf_predictions)\n",
        "print('Random Forest RMSE:', rf_rmse)\n",
        "print('Random Forest MAE:', rf_mae)\n",
        "print('Random Forest R-squared:', rf_r2)\n",
        "\n",
        "# Evaluate Best Random Forest model (after hyperparameter tuning)\n",
        "best_rf_rmse = np.sqrt(mean_squared_error(y_test, best_rf_predictions))\n",
        "best_rf_mae = mean_absolute_error(y_test, best_rf_predictions)\n",
        "best_rf_r2 = r2_score(y_test, best_rf_predictions)\n",
        "print('Best Random Forest RMSE:', best_rf_rmse)\n",
        "print('Best Random Forest MAE:', best_rf_mae)\n",
        "print('Best Random Forest R-squared:', best_rf_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omv8boKfFhlT",
        "outputId": "71abf486-5d87-42be-e4c1-9d7cb0101045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression RMSE: 0.020116351893519513\n",
            "Linear Regression MAE: 0.006641079325823219\n",
            "Linear Regression R-squared: 0.9923921597125268\n",
            "Random Forest RMSE: 0.01727997728825834\n",
            "Random Forest MAE: 0.004688437758800487\n",
            "Random Forest R-squared: 0.9943862990514614\n",
            "Best Random Forest RMSE: 0.01732804197415406\n",
            "Best Random Forest MAE: 0.004676147067757274\n",
            "Best Random Forest R-squared: 0.9943550263217712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Out-of-Sample Data to Validate Model"
      ],
      "metadata": {
        "id": "11YDjHyLax8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing and importing necessary packages\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# fetching new out-of-sample data\n",
        "\n",
        "companies = [\n",
        "    'RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'HINDUNILVR.NS',\n",
        "    'HDFC.NS', 'KOTAKBANK.NS', 'ICICIBANK.NS', 'SBIN.NS', 'BAJFINANCE.NS',\n",
        "    'BHARTIARTL.NS', 'ITC.NS', 'ASIANPAINT.NS', 'HCLTECH.NS', 'MARUTI.NS',\n",
        "    'LT.NS', 'WIPRO.NS', 'AXISBANK.NS', 'ULTRACEMCO.NS', 'SUNPHARMA.NS',\n",
        "    'TITAN.NS', 'ADANIPORTS.NS', 'NESTLEIND.NS', 'ONGC.NS', 'BAJAJFINSV.NS',\n",
        "    'TECHM.NS', 'HDFCLIFE.NS', 'NTPC.NS', 'JSWSTEEL.NS', 'POWERGRID.NS',\n",
        "    'DIVISLAB.NS', 'SBILIFE.NS', 'GRASIM.NS', 'DRREDDY.NS', 'BRITANNIA.NS',\n",
        "    'TATAMOTORS.NS', 'HINDALCO.NS', 'COALINDIA.NS', 'TATASTEEL.NS', 'IOC.NS',\n",
        "    'BAJAJ-AUTO.NS', 'HEROMOTOCO.NS', 'EICHERMOT.NS', 'INDUSINDBK.NS', 'BPCL.NS',\n",
        "    'BHARATIARTL.NS', 'UPL.NS', 'CIPLA.NS', 'SHREECEM.NS', 'ADANIGREEN.NS',\n",
        "    'ADANITRANS.NS', 'M&M.NS', 'TATACONSUM.NS', 'BAJAJHLDNG.NS', 'DABUR.NS',\n",
        "    'GAIL.NS', 'HDFCAMC.NS', 'HINDPETRO.NS', 'NAUKRI.NS', 'BERGEPAINT.NS',\n",
        "    'PIDILITIND.NS', 'SIEMENS.NS', 'DLF.NS', 'BANDHANBNK.NS', 'MUTHOOTFIN.NS',\n",
        "    'ICICIGI.NS', 'SBICARD.NS', 'LUPIN.NS', 'HAVELLS.NS', 'COLPAL.NS',\n",
        "    'AMBUJACEM.NS', 'PGHH.NS', 'GODREJCP.NS', 'PEL.NS', 'MRF.NS',\n",
        "    'BIOCON.NS', 'MARICO.NS', 'INDIGO.NS', 'NMDC.NS', 'BEL.NS',\n",
        "    'APOLLOHOSP.NS', 'JUBLFOOD.NS', 'BOSCHLTD.NS', 'ICICIPRULI.NS', 'GLAND.NS',\n",
        "    'LTI.NS', 'MPHASIS.NS', 'VEDL.NS', 'AUBANK.NS', 'TORNTPHARM.NS',\n",
        "    'ACC.NS', 'TATAPOWER.NS', 'BANKBARODA.NS', 'ATGL.NS', 'MINDTREE.NS',\n",
        "    'PIDILITIND.NS', 'PERSISTENT.NS', 'IGL.NS', 'HAL.NS', 'ICICIBANK.NS'\n",
        "]\n",
        "\n",
        "# adjust this to a date that was not included in train-test data\n",
        "new_start_date = '2023-02-01'\n",
        "# end date is not included in train-test data as well\n",
        "new_end_date = '2023-04-01'\n",
        "new_data = pd.DataFrame()\n",
        "for symbol in companies:\n",
        "    fetched_data = yf.download(symbol, start=new_start_date, end=new_end_date)\n",
        "    fetched_data['Symbol'] = symbol\n",
        "    new_data = new_data.append(fetched_data)\n",
        "\n",
        "new_data.reset_index(inplace=True)\n",
        "\n",
        "# preprocessing the out-of-sample data\n",
        "# convert 'Date' to datetime and sort\n",
        "new_data['Date'] = pd.to_datetime(new_data['Date'])\n",
        "new_data.sort_values(by=['Symbol', 'Date'], inplace=True)\n",
        "new_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# handling missing values\n",
        "new_data.dropna(inplace=True)\n",
        "\n",
        "# removing outliers\n",
        "for column in ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']:\n",
        "    mean = new_data[column].mean()\n",
        "    std = new_data[column].std()\n",
        "    new_data = new_data[(new_data[column] > (mean - 3 * std)) & (new_data[column] < (mean + 3 * std))]\n",
        "\n",
        "# normalizing numerical columns\n",
        "numerical_columns = new_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "scaler = MinMaxScaler()\n",
        "new_data[numerical_columns] = scaler.fit_transform(new_data[numerical_columns])\n",
        "\n",
        "# feature engineering - same as above\n",
        "new_data['Daily_Return'] = (new_data['Close'] - new_data['Open']) / new_data['Open']\n",
        "new_data['High_Low_Range'] = new_data['High'] - new_data['Low']\n",
        "new_data['7Day_MA_Close'] = new_data['Close'].rolling(window=7).mean()\n",
        "new_data['14Day_MA_Close'] = new_data['Close'].rolling(window=14).mean()\n",
        "new_data['7Day_MA_Volume'] = new_data['Volume'].rolling(window=7).mean()\n",
        "\n",
        "delta = new_data['Close'].diff(1)\n",
        "up = delta.clip(lower=0)\n",
        "down = -1 * delta.clip(upper=0)\n",
        "roll_up = up.rolling(window=14).mean()\n",
        "roll_down = down.rolling(window=14).mean()\n",
        "RS = roll_up / roll_down\n",
        "new_data['RSI'] = 100.0 - (100.0 / (1.0 + RS))\n",
        "new_data.dropna(inplace=True)\n",
        "\n",
        "# saving the preprocessed data to a CSV file\n",
        "new_data.to_csv('/content/drive/MyDrive/Fall 2023/Applied Data Science/datasets/out_of_sample_stock_data.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "_8h2XPuEGEv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validating Model and Testing for Generalizability"
      ],
      "metadata": {
        "id": "mXPmfj4Za9K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# loading the out-of-sample dataset\n",
        "file_path = '/content/drive/MyDrive/Fall 2023/Applied Data Science/datasets/out_of_sample_stock_data.csv'  # Adjust the file path if necessary\n",
        "out_of_sample_data = pd.read_csv(file_path)\n",
        "\n",
        "# handling infinite and NaN values in out-of-sample data\n",
        "out_of_sample_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "out_of_sample_data.dropna(inplace=True)\n",
        "\n",
        "# selecting the same features as used in the model training\n",
        "selected_features = ['Volume', 'Daily_Return', 'High_Low_Range', '7Day_MA_Close', '14Day_MA_Close', '7Day_MA_Volume', 'RSI']\n",
        "X_out_sample = out_of_sample_data[selected_features]\n",
        "\n",
        "# predicting using linear regression model that was trained above\n",
        "lr_out_sample_predictions = lr_model.predict(X_out_sample)\n",
        "\n",
        "# predicting using the best random forest model\n",
        "best_rf_out_sample_predictions = best_rf_model.predict(X_out_sample)\n",
        "\n",
        "# evaluating the performance on the out-of-sample data\n",
        "lr_out_sample_mse = mean_squared_error(out_of_sample_data['Close'], lr_out_sample_predictions)\n",
        "lr_out_sample_mae = mean_absolute_error(out_of_sample_data['Close'], lr_out_sample_predictions)\n",
        "lr_out_sample_r2 = r2_score(out_of_sample_data['Close'], lr_out_sample_predictions)\n",
        "\n",
        "best_rf_out_sample_mse = mean_squared_error(out_of_sample_data['Close'], best_rf_out_sample_predictions)\n",
        "best_rf_out_sample_mae = mean_absolute_error(out_of_sample_data['Close'], best_rf_out_sample_predictions)\n",
        "best_rf_out_sample_r2 = r2_score(out_of_sample_data['Close'], best_rf_out_sample_predictions)\n",
        "\n",
        "# printing the evaluation results\n",
        "print('Linear Regression - Out-of-Sample MSE:', lr_out_sample_mse)\n",
        "print('Linear Regression - Out-of-Sample MAE:', lr_out_sample_mae)\n",
        "print('Linear Regression - Out-of-Sample R-squared:', lr_out_sample_r2)\n",
        "\n",
        "print('Random Forest - Out-of-Sample MSE:', best_rf_out_sample_mse)\n",
        "print('Random Forest - Out-of-Sample MAE:', best_rf_out_sample_mae)\n",
        "print('Random Forest - Out-of-Sample R-squared:', best_rf_out_sample_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgOeBwJpWFaY",
        "outputId": "04456d92-dcd9-4376-d82b-091d51179c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - Out-of-Sample MSE: 0.004594872740885675\n",
            "Linear Regression - Out-of-Sample MAE: 0.0284734319152641\n",
            "Linear Regression - Out-of-Sample R-squared: 0.9187099894273586\n",
            "Random Forest - Out-of-Sample MSE: 0.004046743904095051\n",
            "Random Forest - Out-of-Sample MAE: 0.02501343144940093\n",
            "Random Forest - Out-of-Sample R-squared: 0.9284071892086284\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}